{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "849aa228-599d-4b3c-89be-1cff236b2779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c67b2a0-77de-4efe-8b0d-adc675290c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/28 21:06:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff12047-5f4d-4841-9dd5-b0625fee8852",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-01.parquet #jan 2024\n",
    "!rm fhvhv_tripdata_2024-01.parquet\n",
    "df = spark.read.parquet('fhvhv_tripdata_2024-01.parquet')\n",
    "#df.show()\n",
    "df.head(3)\n",
    "df.schema\n",
    "df.printSchema()\n",
    "df.count()\n",
    "df_partitioned = df.repartition(16)\n",
    "df_partitioned.rdd.getNumPartitions()\n",
    "df_partitioned.write.parquet(\"fhv_partitioned\", mode='overwrite')\n",
    "# read the partitioned data\n",
    "df = spark.read.parquet('fhv_partitioned')\n",
    "# lazy / transformation - select, filter, groupby, joins\n",
    "df.select('pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID') \\\n",
    "  .filter(df.hvfhs_license_num == 'HV0003')\n",
    "# eager / actions - #show, take head, write\n",
    "df.select('pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID') \\\n",
    "  .filter(df.hvfhs_license_num == 'HV0003').show(3)\n",
    "\n",
    "# ^just like sql, but pyspark is more flexible\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be648667-68db-42f8-a708-115a10b7fe98",
   "metadata": {},
   "source": [
    "udf - user defined functions\n",
    "\n",
    "- huge list of functions\n",
    "- can also define out own function\n",
    "- and this is not what you would typically do in data warehouses\n",
    "bcz there defining your own fucntions is cumbersome.\n",
    "- with some complicates cases you end with ith a bunch of case statements in sql, making it difficult to test, unlike python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7519f95-f5de-4f7d-820a-7d2d99356c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "F.to_date()\n",
    "def crazy_stuff(base_num):\n",
    "    num = int(base_num[1:])\n",
    "    if num % 7 == 0:\n",
    "        return f's/{num:03x}'\n",
    "    elif num % 3 == 0:\n",
    "        return f'a/{num:03x}'\n",
    "    else:\n",
    "        return f'e/{num:03x}'\n",
    "\n",
    "crazy_stuff('B02884')\n",
    "# convert it to udf using udf()\n",
    "\n",
    "from pyspark.sql import types\n",
    "crazy_stuff_udf = F.udf(crazy_stuff, returnType=types.StringType())\n",
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .withColumn('base_id', crazy_stuff_udf(df.dispatching_base_num)) \\\n",
    "    .select('base_id', 'pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c7032d-b3d0-445e-81d5-d12898ed5eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_yellow = spark.read.parquet('../data/raw/yellow/*/*')\n",
    "df_yellow.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b104f6ad-b0e0-4548-97f2-190113bde9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "int_columns = [\"passenger_count\", \"RatecodeID\", \"payment_type\"]\n",
    "for col in int_columns:\n",
    "    df_yellow = df_yellow.withColumn(col, df_yellow[col].cast(IntegerType()))\n",
    "df_yellow.select('payment_type').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5fd284-6f59-4cdc-bf03-107c91b17c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: data/pq/green/2024/01\n",
      "Processed and saved: data/pq/green/2024/02\n",
      "Processed and saved: data/pq/green/2024/03\n",
      "Processed and saved: data/pq/green/2024/04\n",
      "Processed and saved: data/pq/green/2024/05\n",
      "Processed and saved: data/pq/green/2024/06\n",
      "Processed and saved: data/pq/green/2024/07\n",
      "Processed and saved: data/pq/green/2024/08\n",
      "Processed and saved: data/pq/green/2024/09\n",
      "Processed and saved: data/pq/green/2024/10\n",
      "Processed and saved: data/pq/green/2024/11\n",
      "Processed and saved: data/pq/green/2024/12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "TAXI_TYPE = \"green\"\n",
    "YEAR = \"2024\"\n",
    "INPUT_BASE = f\"data/raw/{TAXI_TYPE}/{YEAR}\"\n",
    "OUTPUT_BASE = f\"data/pq/{TAXI_TYPE}/{YEAR}\"\n",
    "\n",
    "# Columns to cast to IntegerType\n",
    "int_columns = [\"passenger_count\", \"RatecodeID\", \"payment_type\"]\n",
    "\n",
    "# Loop through each month\n",
    "for month in range(1, 13):\n",
    "    month_str = f\"{month:02d}\"\n",
    "    input_path = os.path.join(INPUT_BASE, month_str, f\"{TAXI_TYPE}_tripdata_{YEAR}_{month_str}.parquet\")\n",
    "    output_path = os.path.join(OUTPUT_BASE, month_str)\n",
    "\n",
    "    # Read\n",
    "    df = spark.read.parquet(input_path)\n",
    "\n",
    "    # Cast columns\n",
    "    for col in int_columns:\n",
    "        if col in df.columns:\n",
    "            df = df.withColumn(col, df[col].cast(IntegerType()))\n",
    "\n",
    "    # Write\n",
    "    df.write.mode(\"overwrite\").parquet(output_path)\n",
    "\n",
    "    print(f\"Processed and saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da113201-9133-48d3-9d1d-5c1fcc3148ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- trip_type: long (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "660218"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green = spark.read.parquet('../data/raw/green/*/*')\n",
    "df_green.printSchema()\n",
    "df_green.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe9e9f6-6f98-4d6d-90fb-ff9e7604945e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2465e42-6933-4f59-a0aa-63374f645635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4530404e-4739-44a7-ac66-8671dc0c2184",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11d2ee47-e04d-4c5c-b926-dbc9a808f44f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: long (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nidakey-gcp/spark/spark-3.4.4-bin-hadoop3/python/pyspark/sql/dataframe.py:330: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|service_type|   count|\n",
      "+------------+--------+\n",
      "|       green|  660218|\n",
      "|      yellow|41169720|\n",
      "+------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:======================================>                   (8 + 4) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|service_type|count(1)|\n",
      "+------------+--------+\n",
      "|       green|  660218|\n",
      "|      yellow|41169720|\n",
      "+------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('../data_old/pq/green/*/*')\n",
    "df_green.printSchema()\n",
    "df_yellow = spark.read.parquet('../data_old/pq/yellow/*/*')\n",
    "df_yellow.printSchema()\n",
    "set(df_green.columns) & set(df_yellow.columns)\n",
    "df_green = df_green \\\n",
    "    .withColumnRenamed('lpep_pickup_datetime', 'pickup_datetime') \\\n",
    "    .withColumnRenamed('lpep_dropoff_datetime', 'dropoff_datetime')\n",
    "\n",
    "df_yellow = df_yellow \\\n",
    "    .withColumnRenamed('tpep_pickup_datetime', 'pickup_datetime') \\\n",
    "    .withColumnRenamed('tpep_dropoff_datetime', 'dropoff_datetime')\n",
    "# reorder green df column to math yellow df\n",
    "common_colums = []\n",
    "\n",
    "yellow_columns = set(df_yellow.columns)\n",
    "\n",
    "for col in df_green.columns:\n",
    "    if col in yellow_columns:\n",
    "        common_colums.append(col)\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_green_sel = df_green \\\n",
    "    .select(common_colums) \\\n",
    "    .withColumn('service_type', F.lit('green'))\n",
    "\n",
    "df_yellow_sel = df_yellow \\\n",
    "    .select(common_colums) \\\n",
    "    .withColumn('service_type', F.lit('yellow'))\n",
    "\n",
    "df_trips_data = df_green_sel.unionAll(df_yellow_sel)\n",
    "\n",
    "df_trips_data.groupBy('service_type').count().show()\n",
    "# run sql\n",
    "df_trips_data.registerTempTable('trips_data')\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    service_type,\n",
    "    count(1)\n",
    "FROM\n",
    "    trips_data\n",
    "GROUP BY \n",
    "    service_type\n",
    "\"\"\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b92e3939-7d80-435d-83c9-50fcaae6191d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:===================================================>    (11 + 1) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-----------+---------------------------+-------------------------+\n",
      "|revenue_month|service_type|total_trips|avg_monthly_passenger_count|avg_monthly_trip_distance|\n",
      "+-------------+------------+-----------+---------------------------+-------------------------+\n",
      "|          Apr|       green|      56473|         1.3049463154996788|       12.088635985338115|\n",
      "|          May|       green|      61007|         1.3236911105472384|       14.607664366384167|\n",
      "|          Mar|       green|      57451|         1.3093362719947972|       13.523978520826482|\n",
      "|          Jan|       green|      56569|          1.309158294766151|       31.482167618306956|\n",
      "|          Feb|       green|      53578|           1.30035538005923|       17.665699914143893|\n",
      "|          Jun|       green|      54738|         1.3194231533526373|       13.989549124922332|\n",
      "|          Dec|       green|      53987|         1.3050609545052494|       13.493061662992872|\n",
      "|          Nov|       green|      52214|         1.3140949672118196|        27.14194794499556|\n",
      "|          Sep|       green|      54422|          1.317348913084715|         18.4160593142479|\n",
      "|          Aug|       green|      51806|         1.3291585360997173|       19.697267111917526|\n",
      "|          Oct|       green|      56153|         1.3378770088794305|       11.398341317471901|\n",
      "|          Jul|       green|      51820|         1.3330744259226066|        11.28829911231187|\n",
      "|          Dec|      yellow|    3668381|          1.362440269412254|        5.087812375540815|\n",
      "|          Jan|      yellow|    2964637|         1.3392796891457706|       3.6521902917625706|\n",
      "|          Aug|      yellow|    2979192|         1.3595184752942906|         4.94486028426464|\n",
      "|          Jul|      yellow|    3076876|         1.3545461271309385|        5.111791086153565|\n",
      "|          Jun|      yellow|    3539172|          1.337567778452246|        5.222029584885727|\n",
      "|          Sep|      yellow|    3633025|         1.3032031941127122|        5.741471732233619|\n",
      "|          Apr|      yellow|    3514295|         1.3341422710811892|       5.2838481573116916|\n",
      "|          May|      yellow|    3723843|         1.3233162919603263|        5.367007577924154|\n",
      "+-------------+------------+-----------+---------------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Revenue grouping \n",
    "    --PULocationID AS revenue_zone,\n",
    "    date_format(pickup_datetime, 'MMM') AS month, \n",
    "    service_type, \n",
    "    \n",
    "    count(*) total_trips,\n",
    "    \n",
    "     -- Revenue calculation \n",
    "    SUM(fare_amount) AS revenue_monthly_fare,\n",
    "    SUM(extra) AS revenue_monthly_extra,\n",
    "    SUM(mta_tax) AS revenue_monthly_mta_tax,\n",
    "    SUM(tip_amount) AS revenue_monthly_tip_amount,\n",
    "    SUM(tolls_amount) AS revenue_monthly_tolls_amount,\n",
    "    SUM(improvement_surcharge) AS revenue_monthly_improvement_surcharge,\n",
    "    SUM(total_amount) AS revenue_monthly_total_amount,\n",
    "    SUM(congestion_surcharge) AS revenue_monthly_congestion_surcharge,\n",
    "\n",
    "    -- Additional calculations\n",
    "    AVG(passenger_count) AS avg_monthly_passenger_count,\n",
    "    AVG(trip_distance) AS avg_monthly_trip_distance\n",
    "FROM\n",
    "FROM\n",
    "    trips_data\n",
    "GROUP BY\n",
    "    1, 2, 3\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "839d6fee-72d4-4a07-a8e5-2b6e671f7df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+---------------------------+-------------------------+\n",
      "|revenue_zone|revenue_month|service_type|revenue_monthly_fare|revenue_monthly_extra|revenue_monthly_mta_tax|revenue_monthly_tip_amount|revenue_monthly_tolls_amount|revenue_monthly_improvement_surcharge|revenue_monthly_total_amount|revenue_monthly_congestion_surcharge|avg_monthly_passenger_count|avg_monthly_trip_distance|\n",
      "+------------+-------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+---------------------------+-------------------------+\n",
      "|           4|     May-2024|       green|  131.39999999999998|                  3.0|                    4.5|        14.399999999999999|                         0.0|                                  5.0|                       163.8|                                 7.5|                        1.0|                    2.742|\n",
      "|         173|     Feb-2024|       green|              844.97|                 26.0|                   18.0|                     18.68|                        6.94|                                 37.0|                      952.34|                                 0.0|         1.2553191489361701|       1.3733333333333335|\n",
      "|         259|     Jan-2024|       green|              375.56|                  2.5|                    8.0|                       1.0|          17.060000000000002|                                 11.0|                      411.12|                                 0.0|                        1.0|         4.33909090909091|\n",
      "|         155|     May-2024|       green|               532.0|                  2.5|                   14.5|                     13.28|                       13.88|                                 13.0|                      580.16|                                 0.0|         1.0714285714285714|                     1.32|\n",
      "|         201|     Jan-2024|       green|  125.02000000000001|                  0.0|                    1.5|                       0.0|                        6.94|                                  2.0|                      134.46|                                 0.0|                        1.0|                     7.39|\n",
      "|          76|     Mar-2024|       green|              2781.7|                 13.0|                   86.0|        122.53999999999998|                       32.96|                                 89.0|          3073.1999999999994|                                 0.0|                        1.0|       1.1372916666666668|\n",
      "|          28|     May-2024|       green|               681.1|                 16.5|                   11.5|                    144.13|                        6.94|                                 33.0|           891.1699999999998|                                 0.0|         1.0909090909090908|       2.3106060606060606|\n",
      "|          88|     May-2024|       green|                67.1|                  3.5|                    2.5|                      4.16|                         0.0|                                  3.0|           84.25999999999999|                                 5.0|                        1.0|       2.1666666666666665|\n",
      "|          65|     Mar-2024|       green|   35760.02000000003|              1926.75|                 1353.0|                   5937.05|           99.83999999999999|                               1854.0|           46847.15999999991|                               453.5|          1.092783505154639|       2.8339176910742916|\n",
      "|          71|     Jan-2024|       green|              712.03|                  2.5|                    9.5|                      7.29|                         0.0|                                 33.0|                      759.32|                                 0.0|                        1.0|        3.357878787878788|\n",
      "|         175|     May-2024|       green|                92.0|                  0.0|                    3.0|                       0.0|                        6.94|                                  2.0|                      101.94|                                 0.0|                        1.0|                      0.0|\n",
      "|          35|     Mar-2024|       green|             1384.17|                 8.75|                   46.0|                     13.85|                       20.82|                                 38.0|                     1484.34|                                2.75|         1.1081081081081081|       2.4707692307692306|\n",
      "|         230|     Mar-2024|       green|                54.0|                  0.0|                    3.0|                       0.0|                         0.0|                                  2.0|                        57.0|                                 0.0|                        1.0|                      0.0|\n",
      "|          54|     Mar-2024|       green|  151.32999999999998|                  0.0|                    0.5|                       8.0|                        6.94|                                  4.0|          176.26999999999998|                                2.75|         2.3333333333333335|               11086.9575|\n",
      "|          52|     Jan-2024|       green|   2168.230000000001|               138.25|                   96.5|         355.2099999999999|                         0.0|                                128.0|          2901.4400000000014|                                55.0|         1.0263157894736843|       2.7112403100775184|\n",
      "|         173|     Mar-2024|       green|              918.01|                 13.0|                   16.5|        39.449999999999996|                         0.0|                                 38.3|                     1025.01|                                2.75|         1.1395348837209303|        2.401818181818182|\n",
      "|         236|     Mar-2024|       green|   5283.299999999998|               374.25|                 203.75|        1075.1000000000008|          107.27999999999999|                   328.30000000000007|           7982.229999999993|                              708.25|          1.391812865497076|       2.4452478134110778|\n",
      "|         235|     Mar-2024|       green|              723.11|                  4.5|                   25.5|        25.979999999999997|                       41.64|                                 25.0|                      833.48|                                2.75|         1.0416666666666667|       1.8019999999999998|\n",
      "|          86|     Mar-2024|       green|               172.5|                  0.0|                    4.5|                       0.0|                       13.88|                                  3.0|                      190.88|                                 0.0|                        1.0|                      0.0|\n",
      "|          64|     Mar-2024|       green|                33.5|                  0.0|                    1.5|                       0.0|                         0.0|                                  1.0|                        35.0|                                 0.0|                        1.0|                      0.0|\n",
      "+------------+-------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+---------------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_result = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Revenue grouping \n",
    "    PULocationID AS revenue_zone,\n",
    "    date_format(pickup_datetime, 'MMM-yyyy') AS revenue_month, \n",
    "    service_type, \n",
    "\n",
    "    -- Revenue calculation \n",
    "    SUM(fare_amount) AS revenue_monthly_fare,\n",
    "    SUM(extra) AS revenue_monthly_extra,\n",
    "    SUM(mta_tax) AS revenue_monthly_mta_tax,\n",
    "    SUM(tip_amount) AS revenue_monthly_tip_amount,\n",
    "    SUM(tolls_amount) AS revenue_monthly_tolls_amount,\n",
    "    SUM(improvement_surcharge) AS revenue_monthly_improvement_surcharge,\n",
    "    SUM(total_amount) AS revenue_monthly_total_amount,\n",
    "    SUM(congestion_surcharge) AS revenue_monthly_congestion_surcharge,\n",
    "\n",
    "    -- Additional calculations\n",
    "    AVG(passenger_count) AS avg_monthly_passenger_count,\n",
    "    AVG(trip_distance) AS avg_monthly_trip_distance\n",
    "FROM\n",
    "    trips_data\n",
    "GROUP BY\n",
    "    1, 2, 3\n",
    "\"\"\")\n",
    "\n",
    "# df_result.show()\n",
    "# df_result.coalesce(1).write.parquet('data/report/', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41fd20dc-1fa5-4ac6-b5b0-11333d87c517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/25 19:33:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://de-vm.asia-south1-c.c.velvety-tangent-463717-h8.internal:7077\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "# spark://de-vm.asia-south1-c.c.velvety-tangent-463717-h8.internal:7077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71bfc361-f7dd-40ab-ace5-96a6910664c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/25 19:35:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "25/06/25 19:36:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "25/06/25 19:36:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "25/06/25 19:36:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('data/pq/green/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257c673d-dc19-4241-ba16-7ae841548df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b3bf08-5530-4597-8c84-e5cfa84566c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19611b7e-ab73-42f2-b248-dcd39df7c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head taxi_zone_lookup.csv\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi_zone_lookup.csv')\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi_zone_lookup.csv')\n",
    "\n",
    "df.show()\n",
    "df.write.parquet('zones')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
